{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classic\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "#import tables\n",
    "import scipy.stats\n",
    "\n",
    "# some nice formating things\n",
    "plt.rc('font', family='serif', size=25)\n",
    "plt.rc('legend', fontsize=25)\n",
    "plt.rc('axes', labelsize=25)\n",
    "plt.rc('axes', titlesize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the HESE event sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadEvents(filename):\n",
    "    E,EerrMin,EerrMax,DEC,RA,Anger = np.loadtxt(filename,comments='#',usecols=(1,2,3,5,6,7), unpack =True)\n",
    "    topo = np.loadtxt(filename,comments='#',usecols=[8], unpack =True, dtype = 'str')\n",
    "    \n",
    "    array = np.recarray(len(E), [('topology', topo.dtype),\n",
    "                                 ('energy', float),\n",
    "                                 ('energy_error', float),\n",
    "                                 ('RA', float),\n",
    "                                 ('DEC', float),\n",
    "                                 ('angular_error', float)])\n",
    "    array.topology[:] = topo\n",
    "    array.energy[:], array.energy_error[:] = E, np.array([EerrMin, EerrMax]).max(axis=0)\n",
    "    array.RA[:], array.DEC[:], array.angular_error[:] = np.radians(RA), np.radians(DEC), np.radians(Anger)\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HESEEvents=loadEvents(\"dataExB/eventsummary_4years.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadCatalog(filename):\n",
    "    DEC,RA = np.loadtxt(filename,comments='#',usecols=(1,2), unpack =True)\n",
    "    NAMES = np.loadtxt(filename,comments='#',usecols=[0], unpack =True, dtype = 'str')\n",
    "    \n",
    "    array = np.recarray(len(DEC), [('name', NAMES.dtype), ('RA', float), ('DEC', float)])\n",
    "    array.name[:] = NAMES\n",
    "    array.DEC[:], array.RA[:] = np.radians(DEC), np.radians(RA)\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catalog=loadCatalog(\"dataExB/SourceListA.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct angular distribution of the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sph_dot(th1,th2,phi1,phi2):\n",
    "    return np.sin(th1)*np.sin(th2)*np.cos(phi1-phi2) + np.cos(th1)*np.cos(th2)\n",
    "\n",
    "# Implementation of the kent distribution\n",
    "def event_angular_distribution(event,source):\n",
    "    kappa = 1./(event.angular_error)**2\n",
    "    log_dist = np.log(kappa) - np.log(2*np.pi) - kappa + kappa*sph_dot(np.pi/2-event.DEC, np.pi/2-source.DEC, event.RA, source.RA)\n",
    "    return np.exp(log_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following likelihood definition\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\xi) = \\prod_{e}^N\\left[ \\frac{1}{M}\\sum_c^M S_{e,c} \\xi + (1-\\xi)B) \\right]\n",
    "\\end{equation}\n",
    "where $\\xi = 0$ is the null hypothesis and is bounded to be between zero and one, $S$ accounts for the event angular distribution, $B$ is the background distribution which we will assume isotropic. Also N is the number of events and M is the number of sources in the catalog. Go ahead ahd construct the $\\log\\mathcal{L}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LLH(ns,catalog_,events_):\n",
    "    N = len(events_)\n",
    "    return np.sum([np.log(np.average((ns/N)*event_angular_distribution(events_,source)) + (1.-ns/N)*(1./(4*np.pi)))\n",
    "                   for source in catalog_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bayesian construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bayes factor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do bayesian hypothesis testing by means of the Bayes factor ($B$), which in this case is defined as \n",
    "\\begin{equation}\n",
    "B_{10} = \\frac{\\int_\\xi d\\xi\\mathcal{L}(\\xi) \\pi(\\xi)}{\\mathcal{L}(0)}\n",
    "\\end{equation}\n",
    "where we have introduce the prior on $\\xi$. Choose a *reasonable* prior and calculate the bayes factor for several catalog. We will use the Jeffrey scale to evaluate the strenght of the evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"jeffrey_scale.png\",width=400,height=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Prior(ns):\n",
    "    return 1./len(HESEEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalculateBayesFactor(catalog_,events_):\n",
    "    IntegratedBayes = np.sum(np.exp([LLH(1.0*ns,catalog_,events_) + np.log(Prior(ns))\n",
    "                                     for ns in range(len(events_))]))\n",
    "    BayesFactor = IntegratedBayes/np.exp(LLH(0.,catalog_,events_))\n",
    "    return BayesFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21648142306813881"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog=loadCatalog(\"dataExB/SL_TeVCat.txt\")\n",
    "CalculateBayesFactor(catalog,HESEEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evs = HESEEvents.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = np.recarray(len(catalogOne)+len(catalog_sc), [('name', catalogOne.name.dtype), ('RA', float), ('DEC', float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array[:len(catalogOne)].RA = catalogOne.RA\n",
    "array[:len(catalogOne)].DEC = catalogOne.DEC\n",
    "array[len(catalogOne):].RA = catalog_sc.RA[:len(catalog_sc)]\n",
    "array[len(catalogOne):].DEC = catalog_sc.DEC[:len(catalog_sc)]\n",
    "#array[len(catalogOne):len(catalogOne)+len(catalog_sc)].RA = catalog_sc.RA[:len(catalog_sc)]\n",
    "#array[len(catalogOne):len(catalogOne)+len(catalog_sc)].DEC = catalog_sc.DEC[:len(catalog_sc)]\n",
    "#array[len(catalogOne)+len(catalog_sc):].RA = catalog_sc2.RA[:len(catalog_sc2)]\n",
    "#array[len(catalogOne)+len(catalog_sc):].DEC = catalog_sc2.DEC[:len(catalog_sc2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carguelles/Library/Python/2.7/lib/python/site-packages/ipykernel/__main__.py:4: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalculateBayesFactor(array[20:],HESEEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalog_sc = catalog.copy()\n",
    "catalog_sc.RA = np.random.uniform(0,2.0*np.pi,len(catalog_sc))  \n",
    "catalog_sc.DEC = np.random.uniform(-np.pi/2.,np.pi/2.,len(catalog_sc))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catalog_sc2 = catalog.copy()\n",
    "catalog_sc2.RA = np.random.uniform(0,2.0*np.pi,len(catalog_sc))  \n",
    "catalog_sc2.DEC = np.random.uniform(-np.pi/2.,np.pi/2.,len(catalog_sc))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135774294377.7952"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalogOne=loadCatalog(\"dataExB/SourceListA.txt\")\n",
    "CalculateBayesFactor(catalogOne,HESEEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(catalogOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55087309330767912.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalogOne=loadCatalog(\"dataExB/SourceListOne.txt\")\n",
    "CalculateBayesFactor(catalogOne,HESEEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11724739305286297"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalogTwo=loadCatalog(\"dataExB/SourceListTwo.txt\")\n",
    "CalculateBayesFactor(catalogTwo,HESEEvents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The frequentist construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestStatistics definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the following test statistic (TS) definition\n",
    "\\begin{equation}\n",
    "\\log\\mathcal{TS} = \\max_\\xi \\log\\mathcal{L}(\\xi) - \\log\\mathcal{L}(\\xi=0).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetTS(catalog_,events_, ns_seed = 0.5):\n",
    "    N = float(len(events_))\n",
    "\n",
    "    maxLLH = -sp.optimize.minimize(lambda ns: -LLH(1.0*ns,catalog_,events_),\n",
    "                                                   np.array([ns_seed]),method='L-BFGS-B',\n",
    "                                                   bounds=np.array([[0.,N]]), jac=False).fun\n",
    "    return (maxLLH-LLH(0.,catalog_,events_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the TS distribution under the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to construct the TS distribution for a given catalog and event set, we construct event realization that would have arised from the null hypothesis and then evaluate the TS. To construct those realization we use the *scrambling* procedure where we randomize the right asension (RA) for each of the events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ObtainTSDistribution(catalog_,events_,trials = 1000):\n",
    "    events_scramble = events_.copy()\n",
    "    ns_min_list = np.zeros(trials)\n",
    "\n",
    "    for i in range(trials):\n",
    "        events_scramble.RA = np.random.uniform(0,2.0*np.pi,len(events_))    \n",
    "        ns_min_list[i] = GetTS(catalog_,events_scramble)\n",
    "    return ns_min_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the frequentist p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the frequentist p-value use the TS distribution to calculate\n",
    "\\begin{equation}\n",
    "p_{value} = \\mathcal{P}(TS>TS_{data})\n",
    "\\end{equation}\n",
    "where $TS_{data}$ is the value of the TS evaluated at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetPValue(catalog_,events_, trials = 100):\n",
    "    TSDistribution_ = ObtainTSDistribution(catalog_,events_, trials = trials)\n",
    "    TSData_ = GetTS(catalog_,events_)\n",
    "    p_value = 1.*np.sum((TSDistribution_ > TSData_))/len(TSDistribution_)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetPValue(catalog,HESEEvents, trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetPValue(array[20:],HESEEvents, trials = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetPValue(catalogTwo,HESEEvents, trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
